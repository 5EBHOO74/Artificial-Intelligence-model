{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " First 5 data on the x axis\n",
      " [[0.5488135 ]\n",
      " [0.71518937]\n",
      " [0.60276338]\n",
      " [0.54488318]\n",
      " [0.4236548 ]] \n",
      "\n",
      " Frist 5 data on the y axis\n",
      " [[5.74406752]\n",
      " [6.57594683]\n",
      " [6.01381688]\n",
      " [5.72441591]\n",
      " [5.118274  ]]\n",
      "\n",
      "Slope: [[5.]]\n",
      "Intercept: [3.]\n",
      "Mean absolute error: 0.00\n",
      "Mean squared error: 0.00\n",
      "Root mean squared error: 0.00\n",
      "R2 score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# let 's imports the necessary packages\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn. linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "\n",
    "# let 's generate random dataset with numpy\n",
    "np. random. seed(0)\n",
    "\n",
    "x = np.random.rand(100, 1)\n",
    "y=3+5*x\n",
    "\n",
    "print('\\n First 5 data on the x axis\\n', x[:5], '\\n\\n Frist 5 data on the y axis\\n',y[:5])\n",
    "\n",
    "# initialise linear regression Model\n",
    "lr_regress= LinearRegression()\n",
    "\n",
    "# fit regression model\n",
    "lr_regress.fit(x, y)# you can add .reshape(-1, 1) to convert into a single array matrix if error appears\n",
    "\n",
    "#predict model\n",
    "y_pred = lr_regress.predict(x)\n",
    "#print(y_pred)\n",
    "\n",
    "# evaluate evaluation\n",
    "\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "# printing the model evaluation values\n",
    "print('\\nSlope:' ,lr_regress.coef_)\n",
    "print('Intercept:', lr_regress.intercept_)\n",
    "print('Mean absolute error: {:.2f}'.format(mae) )\n",
    "print('Mean squared error: {:.2f}'.format(mse) )\n",
    "print('Root mean squared error: {:.2f}'.format(rmse) )\n",
    "print('R2 score: ', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting all values\n",
    "\n",
    "# plot the data points for x and y\n",
    "plt.scatter(x, y, s=10)\n",
    "plt.xlabel('x')\n",
    "\n",
    "plt.ylabel('y')\n",
    "\n",
    "\n",
    "# predicted values\n",
    "plt.plot(x, y_pred, color='r')\n",
    "plt.show()# plotting all values\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model_year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   origin                   car_name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "\n",
      "These are instances with missing data \n",
      " Empty DataFrame\n",
      "Columns: [mpg, cylinders, displacement, horsepower, weight, acceleration, model_year, origin, car_name]\n",
      "Index: []\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   displacement  398 non-null    float64\n",
      " 3   horsepower    398 non-null    object \n",
      " 4   weight        398 non-null    int64  \n",
      " 5   acceleration  398 non-null    float64\n",
      " 6   model_year    398 non-null    int64  \n",
      " 7   origin        398 non-null    int64  \n",
      " 8   car_name      398 non-null    object \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 28.1+ KB\n",
      "\n",
      " None\n",
      "\n",
      "These are instances with missing data after conversion to float \n",
      "       mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
      "32   25.0          4          98.0         NaN    2046          19.0   \n",
      "126  21.0          6         200.0         NaN    2875          17.0   \n",
      "330  40.9          4          85.0         NaN    1835          17.3   \n",
      "336  23.6          4         140.0         NaN    2905          14.3   \n",
      "354  34.5          4         100.0         NaN    2320          15.8   \n",
      "374  23.0          4         151.0         NaN    3035          20.5   \n",
      "\n",
      "     model_year  origin              car_name  \n",
      "32           71       1            ford pinto  \n",
      "126          74       1         ford maverick  \n",
      "330          80       2  renault lecar deluxe  \n",
      "336          80       1    ford mustang cobra  \n",
      "354          81       2           renault 18i  \n",
      "374          82       1        amc concord dl  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', ' model_year', 'origin', 'car_name')",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\PycharmProjects\\COM724NEW\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\PycharmProjects\\COM724NEW\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\COM724NEW\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: ('cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', ' model_year', 'origin', 'car_name')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 69>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     64\u001B[0m train_headers \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcylinders\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdisplacement\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhorsepower\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124macceleration\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m model_year\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     65\u001B[0m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124morigin\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcar_name\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     67\u001B[0m target_header \u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmpg\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m---> 69\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mautompg_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrain_headers\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     70\u001B[0m y \u001B[38;5;241m=\u001B[39m autompg_data[target_header]\n\u001B[0;32m     72\u001B[0m \u001B[38;5;66;03m#get the displacement variable which allows us to carry our simple regression\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\COM724NEW\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3505\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3507\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\PycharmProjects\\COM724NEW\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3623\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3624\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3625\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3626\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3627\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3628\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: ('cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', ' model_year', 'origin', 'car_name')"
     ]
    }
   ],
   "source": [
    "# let 's imports the necessary packages\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "import matplotlib.pyplot as pit\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn. impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn. linear_model import LinearRegression\n",
    "\n",
    "# declaring header names\n",
    "autompg_headers = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year',\n",
    "'origin', 'car_name']\n",
    "\n",
    "#read the data using the read_csv class of pandas\n",
    "autompg_data = read_csv('auto_mpg_data.csv', names=autompg_headers)\n",
    "\n",
    "print(autompg_data.head(5)) #you may want to check the data loaded\n",
    "\n",
    "check_missing_data = autompg_data[autompg_data. isna().any(axis=1)]\n",
    "print('\\nThese are instances with missing data \\n', check_missing_data) # print instances with missing data\n",
    "\n",
    "#no missing data shown at the momement since ? is not classified as null(NAN)\n",
    "\n",
    "#let's print the data information\n",
    "print('\\n',autompg_data. info()) # or simply check the dtypes using autompg_data.dtypes\n",
    "\n",
    "#since we know that the horsepoiwer variable contains the ? values, we can convert object to float\n",
    "\n",
    "#autompg_data['horsepower'] = autompg_data['horsepower' ].astype( float)\n",
    "autompg_data['horsepower'] = pd.to_numeric(autompg_data['horsepower'],errors='coerce')\n",
    "# convert horsepower to float\n",
    "\n",
    "# Now let's re-check our dataframe for missing values\n",
    "\n",
    "missing_data = autompg_data[autompg_data. isna().any(axis=1)]\n",
    "\n",
    "print('\\nThese are instances with missing data after conversion to float \\n', missing_data)\n",
    "#missing values are now printed\n",
    "\n",
    "#use the simpleImputer function to replace missing value (NAN)\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent' )# you may replace with most_frequent median, mean and observe\n",
    "imputer. fit(autompg_data)\n",
    "\n",
    "new_data = imputer.transform(autompg_data)\n",
    "\n",
    "#reassign the new dataframe\n",
    "autompg_data = pd.DataFrame(data=new_data, columns=autompg_headers)\n",
    "\n",
    "#seperate the data into X(train) and y(test) groups - training and target sets\n",
    "\n",
    "train_headers = ('cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', ' model_year',\n",
    "'origin', 'car_name')\n",
    "\n",
    "target_header =['mpg']\n",
    "\n",
    "X = autompg_data[train_headers]\n",
    "y = autompg_data[target_header]\n",
    "\n",
    "#get the displacement variable which allows us to carry our simple regression\n",
    "x = autompg_data.iloc[:, 2].values # or x = autompg_data['displacement']\n",
    "\n",
    "#get the mpg\n",
    "y = autompg_data.iloc[:, 0].values\n",
    "\n",
    "print('\\nprint x dimension', x.shape)\n",
    "print('\\nprint y dimension', y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The total of training dataset (278, 1)\n",
      "\n",
      " The total of test dataset (120, 1)\n"
     ]
    }
   ],
   "source": [
    "#Simple Linear Regression\n",
    "\n",
    "# let 's imports the necessary packages\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn. impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# declaring header names\n",
    "autompg_headers = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year',\n",
    "'origin', 'car_name']\n",
    "\n",
    "#read the data using the read_csv class of pandas\n",
    "autompg_data = read_csv('auto_mpg_data.csv', names=autompg_headers)\n",
    "\n",
    "check_missing_data = autompg_data[autompg_data. isna().any(axis=1)]\n",
    "#no missing data shown at the moment since ? is not classified as null(NAN)\n",
    "\n",
    "#since we know that the horsepoiwer variable contains the ? values, we can convert object to float\n",
    "\n",
    "#autompg_data['horsepower'] = autompg_data['horsepower'].astype( float)\n",
    "autompg_data['horsepower'] = pd.to_numeric(autompg_data['horsepower'],errors='coerce')# convert horsepower to float\n",
    "\n",
    "# Now let's re-check our dataframe for missing values\n",
    "missing_data = autompg_data[autompg_data. isna().any(axis=1)]\n",
    "#missing values are now printed\n",
    "\n",
    "#use the simpleImputer function to replace missing value (NAN)\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent' )# you may replace with most_frequent median, mean and observe\n",
    "imputer. fit (autompg_data)\n",
    "\n",
    "new_data = imputer.transform(autompg_data)\n",
    "\n",
    "#reassign the new dataframe\n",
    "autompg_data = pd.DataFrame(data=new_data, columns=autompg_headers)\n",
    "\n",
    "#seperate the data into X(train) and y(test) groups - training and target sets\n",
    "\n",
    "train_headers = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year',\n",
    "'origin', 'car_name']\n",
    "\n",
    "target_header =['mpg']\n",
    "\n",
    "x = autompg_data[target_header]\n",
    "y = autompg_data[target_header]\n",
    "\n",
    "#get the displacement variable which allows us to carry our simple regression\n",
    "x = autompg_data.iloc[:, 2].values.reshape((-1, 1)) #reshape as model may expect 2D\n",
    "# or x = autompg_data['displacement' ]\n",
    "\n",
    "#get the mpg\n",
    "y = autompg_data.iloc[:, 0].values\n",
    "#print(y)\n",
    "\n",
    "#split data into 70:3@ train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "\n",
    "#check the dimensions of train and test data\n",
    "print('\\n The total of training dataset',x_train. shape)\n",
    "print('\\n The total of test dataset',x_test.shape)\n",
    "\n",
    "#Let perform a linear regression for displacement and mpg\n",
    "# initialise linear regression Model\n",
    "lr_regress= LinearRegression()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 10>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m lr_regress\u001B[38;5;241m.\u001B[39mpredict(x_test)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m#predict model on train data\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m y_pred_train \u001B[38;5;241m=\u001B[39m \u001B[43mdt_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# evaluate evaluation\u001B[39;00m\n\u001B[0;32m     14\u001B[0m mae \u001B[38;5;241m=\u001B[39m mean_absolute_error(y_test, y_pred)\n",
      "File \u001B[1;32m~\\PycharmProjects\\COM724NEW\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py:504\u001B[0m, in \u001B[0;36mBaseDecisionTree.predict\u001B[1;34m(self, X, check_input)\u001B[0m\n\u001B[0;32m    481\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m    482\u001B[0m     \u001B[38;5;124;03m\"\"\"Predict class or regression value for X.\u001B[39;00m\n\u001B[0;32m    483\u001B[0m \n\u001B[0;32m    484\u001B[0m \u001B[38;5;124;03m    For a classification model, the predicted class for each sample in X is\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;124;03m        The predicted classes, or the predict values.\u001B[39;00m\n\u001B[0;32m    503\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 504\u001B[0m     \u001B[43mcheck_is_fitted\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_X_predict(X, check_input)\n\u001B[0;32m    506\u001B[0m     proba \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtree_\u001B[38;5;241m.\u001B[39mpredict(X)\n",
      "File \u001B[1;32m~\\PycharmProjects\\COM724NEW\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1345\u001B[0m, in \u001B[0;36mcheck_is_fitted\u001B[1;34m(estimator, attributes, msg, all_or_any)\u001B[0m\n\u001B[0;32m   1340\u001B[0m     fitted \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   1341\u001B[0m         v \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mvars\u001B[39m(estimator) \u001B[38;5;28;01mif\u001B[39;00m v\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m v\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1342\u001B[0m     ]\n\u001B[0;32m   1344\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fitted:\n\u001B[1;32m-> 1345\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NotFittedError(msg \u001B[38;5;241m%\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(estimator)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m})\n",
      "\u001B[1;31mNotFittedError\u001B[0m: This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# fit regression model\n",
    "\n",
    "lr_regress.fit(x_train, y_train)\n",
    "\n",
    "#predict model\n",
    "y_pred = lr_regress.predict(x_test)\n",
    "\n",
    "#predict model on train data\n",
    "y_pred_train = dt_model.predict(x_train)\n",
    "\n",
    "# evaluate evaluation\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# printing the model evaluation values\n",
    "print('\\nSlope:' ,lr_regress.coef_)\n",
    "print('Intercept:', lr_regress.intercept_)\n",
    "print('Mean absolute error: {:.2f}'.format(mae) )\n",
    "print('Mean squared error: {:.2f}'.format(mse) )\n",
    "print('Root mean squared error: {:.2f}'.format(rmse) )\n",
    "print('R2 score: ', r2)\n",
    "\n",
    "# plotting all values\n",
    "\n",
    "# plot the data points for x and y\n",
    "plt.scatter(x_test, y_test, s=10)\n",
    "plt.xlabel('x - Displacement')\n",
    "plt.ylabel('y — MPG')\n",
    "\n",
    "# predicted values\n",
    "plt.plot(x_test, y_pred, color='r')\n",
    "plt.show()\n",
    "\n",
    "#we can check prediction for a specific values\n",
    "pred_my_value = lr_regress.predict([[171.0]])\n",
    "print(\"This is the prediction \", pred_my_value, '\\n')\n",
    "\n",
    "# Multiple Linear Regression\n",
    "\n",
    "#let 's imports the mecessary packages\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn. linear_model import LinearRegression\n",
    "\n",
    "# declaring header names\n",
    "autompg_headers = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year',\n",
    "'origin', 'car_name']\n",
    "\n",
    "#read the data using the read_csv class of pandas\n",
    "autompg_data = read_csv('venv/auto_mpg_data.csv', names=autompg_headers)\n",
    "\n",
    "check_missing_data = autompg_data[autompg_data. isna().any(axis=1)]\n",
    "#no missing data shown at the momement since ? is not classified as null (NAN)\n",
    "\n",
    "#since we know that the horsepoiwer variable contains the ? values, we can convert object to float\n",
    "\n",
    "#autompg_data['horsepower'] = autompg_data['horsepower' ].astype( float)\n",
    "autompg_data['horsepower'] = pd.to_numeric(autompg_data['horsepower'],errors='coerce')# convert horsepower to float\n",
    "\n",
    "# Now Let's re-check our dataframe for missing values\n",
    "missing_data = autompg_data[autompg_data. isna().any(axis=1)]\n",
    "#missing values are now printed\n",
    "\n",
    "#use the simpleImputer function to replace missing value (NAN)\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent' )# you may replace with most_frequent median, mean and observe\n",
    "imputer. fit(autompg_data)\n",
    "\n",
    "new_data = imputer.transform(autompg_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The total of training dataset (278, 1)\n",
      "\n",
      " The total of test dataset (120, 1)\n",
      "\n",
      "Slope: [-0.39912226  0.02232034 -0.014257   -0.0071813   0.08704964  0.79702551\n",
      "  1.15658328]\n",
      "Intercept: -19.449513538151304\n",
      "Mean absolute error: 2.31\n",
      "Mean squared error: 8.97\n",
      "Root mean squared error: 2.99\n",
      "R2 score:  0.8466472315667266\n",
      "This is the prediction  [21.35631026] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reassign the new dataframe\n",
    "autompg_data = pd.DataFrame(data=new_data, columns=autompg_headers)\n",
    "\n",
    "#seperate the data into X(train) and y(test) groups - training and target sets\n",
    "\n",
    "train_headers = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year',\n",
    "'origin','car_name']\n",
    "\n",
    "target_header =['mpg']\n",
    "\n",
    "X = autompg_data[train_headers]\n",
    "y = autompg_data[target_header]\n",
    "\n",
    "#get the variable which allows us to carry out multiple linear regression\n",
    "X = autompg_data.iloc[:, 1:8].values #drop the car name as due to high caridnality and not being a strong predictive\n",
    "# or x = autompg_data['displacement' ]\n",
    "\n",
    "#get the mpg\n",
    "y = autompg_data.iloc[:, 0].values\n",
    "\n",
    "#split data into 7@:3@ train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "#check the dimensions of train and test data\n",
    "print('\\n The total of training dataset',x_train. shape)\n",
    "print('\\n The total of test dataset',x_test.shape)\n",
    "\n",
    "# initialise linear regression Model\n",
    "lr_regress= LinearRegression()\n",
    "\n",
    "# fit regression model\n",
    "lr_regress.fit(X_train, y_train) # you can add .reshape(-1, 1) to convert into a single array matrix if error appear\n",
    "\n",
    "#predict model\n",
    "y_pred = lr_regress.predict(X_test)\n",
    "#print(y_pred)\n",
    "\n",
    "#predict model on train data\n",
    "y_pred_train = lr_regress.predict(X_train)\n",
    "\n",
    "\n",
    "\n",
    "# evaluate evaluation\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# printing the model evaluation values\n",
    "print('\\nSlope:' ,lr_regress.coef_)\n",
    "print('Intercept:', lr_regress.intercept_)\n",
    "print('Mean absolute error: {:.2f}'.format(mae) )\n",
    "print('Mean squared error: {:.2f}'. format(mse) )\n",
    "print('Root mean squared error: {:.2f}'.format(rmse) )\n",
    "print('R2 score: ', r2)\n",
    "\n",
    "#we can check prediction for a specific values\n",
    "pred_my_value = lr_regress.predict([[6, 171.0, 97.0, 2984, 14.5, 75, 1]])\n",
    "print(\"This is the prediction \", pred_my_value, '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3597418375.py, line 73)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Input \u001B[1;32mIn [13]\u001B[1;36m\u001B[0m\n\u001B[1;33m    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=@.3, random_state=1)\u001B[0m\n\u001B[1;37m                                                                        ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "\n",
    "#let 's imports the necessary packages\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn. impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# declaring header names\n",
    "autompg_headers = ('mpg', 'cylinders', 'displacement', 'horsepower', 'weight' 'acceleration', 'model_year',\n",
    "'origin', 'car_name')\n",
    "\n",
    "#read the data using the read_csv class of pandas\n",
    "autompg_data = read_csv('venv/auto_mpg_data.csv', names=autompg_headers)\n",
    "\n",
    "check_missing_data = autompg_data[autompg_data. isna().any(axis=1)]\n",
    "#no missing data shown at the momement since ? is not classified as null(NAN)\n",
    "\n",
    "#since we know that the horsepoiwer variable contains the ? values, we can convert object to float\n",
    "\n",
    "#autompg_data['horsepower'] = autompg_data[‘horsepower' ].astype( float)\n",
    "autompg_data['horsepower'] = pd. to_numeric(autompg_data['horsepower'],errors='coerce')\n",
    "# convert horsepower to float\n",
    "\n",
    "# Now let's re-check our dataframe for missing values\n",
    "missing_data = autompg_data[autompg_data. isna().any(axis=1)]\n",
    "#missing values are now printed\n",
    "\n",
    "#use the simpleImputer function to replace missing value (NAN)\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent' )# you may replace with most_frequent median, mean and observe\n",
    "imputer. fit(autompg_data)\n",
    "\n",
    "new_data = imputer.transform(autompg_data)\n",
    "\n",
    "#reassign the new dataframe\n",
    "autompg_data = pd.DataFrame(data=new_data, columns=autompg_headers)\n",
    "\n",
    "#seperate the data into X(train) and y(test) groups - training and target sets\n",
    "train_headers = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year',\n",
    "'origin','car_name']\n",
    "\n",
    "target_header =['mpg']\n",
    "\n",
    "X = autompg_data[train_headers]\n",
    "y = autompg_data[target_header]\n",
    "\n",
    "#get the indepedent variables\n",
    "X = autompg_data.iloc[:, 1:8].values #drop the car name as due to high caridnality and not being a strong predictive\n",
    "# or x = autompg_data['displacement' ]\n",
    "\n",
    "#get the mpg target variable\n",
    "y = autompg_data.iloc[:, 0].values\n",
    "\n",
    "#split data into 70:30 train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=@.3, random_state=1)\n",
    "\n",
    "#check the dimensions of train and test data\n",
    "print('\\n The total of training dataset',x_train. shape)\n",
    "print('\\n The total of test dataset',x_test.shape)\n",
    "\n",
    "# initialise decision regression Model\n",
    "dt_model = DecisionTreeRegressor(max_depth= 8, min_samples_leaf= 0.13,random_state=1)\n",
    "dt_model =DecisionTreeRegressor( )\n",
    "\n",
    "# fit regression model\n",
    "dt_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#predict model on test data\n",
    "y_pred = dt_model.predict(X_test)\n",
    "#print(y_pred)\n",
    "\n",
    "#predict model on train data\n",
    "y_pred_train = dt_model.predict(X_train)\n",
    "\n",
    "# evaluate evaluation\n",
    "\n",
    "Mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# printing the model evaluation values\n",
    "\n",
    "print('Mean absolute error: {:.2f}'.format(mae))\n",
    "print('Mean squared error: {:.2f}'. format(mse) )\n",
    "print('Root mean squared error: {:.2f}'.format(rmse) )\n",
    "print('R2 score:{:.2f}'.format(r2))\n",
    "\n",
    "#we can check prediction for a specific values\n",
    "pred_my_value = dt_model.predict([[6, 171.0, 97.0, 2984, 14.5, 75, 1]])\n",
    "print(\"This is the prediction \", pred_my_value, '\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 3.40\n",
      "Mean squared error: 18.77\n",
      "Root mean squared error: 4.33\n",
      "R2 score:0.68\n",
      "R2 score Train data: 0.65\n",
      "\n",
      "This is the prediction [17.22248062] \n",
      "\n",
      "Mean absolute error: 1.92\n",
      "Mean squared error: 7.31\n",
      "Root mean squared error: 4.33\n",
      "R2 score:0.87\n",
      "R2 score Train data: 0.98\n",
      "\n",
      "This is the prediction  [20.7] \n",
      "\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 105>\u001B[1;34m()\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mThis is the prediction \u001B[39m\u001B[38;5;124m\"\u001B[39m, pred_my_value, \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    104\u001B[0m \u001B[38;5;66;03m#we can check prediction for a specific values\u001B[39;00m\n\u001B[1;32m--> 105\u001B[0m pred_my_value \u001B[38;5;241m=\u001B[39m \u001B[43mdt_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m171.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m97.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2984\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m14.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m75\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mThis is the prediction \u001B[39m\u001B[38;5;124m\"\u001B[39m, pred_my_value, \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\COM724NEW\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py:504\u001B[0m, in \u001B[0;36mBaseDecisionTree.predict\u001B[1;34m(self, X, check_input)\u001B[0m\n\u001B[0;32m    481\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m    482\u001B[0m     \u001B[38;5;124;03m\"\"\"Predict class or regression value for X.\u001B[39;00m\n\u001B[0;32m    483\u001B[0m \n\u001B[0;32m    484\u001B[0m \u001B[38;5;124;03m    For a classification model, the predicted class for each sample in X is\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;124;03m        The predicted classes, or the predict values.\u001B[39;00m\n\u001B[0;32m    503\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 504\u001B[0m     \u001B[43mcheck_is_fitted\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_X_predict(X, check_input)\n\u001B[0;32m    506\u001B[0m     proba \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtree_\u001B[38;5;241m.\u001B[39mpredict(X)\n",
      "File \u001B[1;32m~\\PycharmProjects\\COM724NEW\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1345\u001B[0m, in \u001B[0;36mcheck_is_fitted\u001B[1;34m(estimator, attributes, msg, all_or_any)\u001B[0m\n\u001B[0;32m   1340\u001B[0m     fitted \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   1341\u001B[0m         v \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mvars\u001B[39m(estimator) \u001B[38;5;28;01mif\u001B[39;00m v\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m v\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1342\u001B[0m     ]\n\u001B[0;32m   1344\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fitted:\n\u001B[1;32m-> 1345\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NotFittedError(msg \u001B[38;5;241m%\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(estimator)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m})\n",
      "\u001B[1;31mNotFittedError\u001B[0m: This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "#declare SEED variable and set to 1 for reproducibility\n",
    "SEED =1\n",
    "\n",
    "# initialise decision tree regression Model\n",
    "dt_model = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.26, random_state=SEED)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt_model. fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the training set\n",
    "y_pred_train = dt_model.predict(X_train)\n",
    "\n",
    "#predict model\n",
    "y_pred = dt_model.predict(X_test)\n",
    "#print(y_pred)\n",
    "\n",
    "# evaluate evaluation\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "#the r2 for the train dataset\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "# printing the model evaluation values\n",
    "\n",
    "print('Mean absolute error: {:.2f}'.format(mae) )\n",
    "print('Mean squared error: {:.2f}'.format(mse) )\n",
    "print('Root mean squared error: {:.2f}'.format(rmse) )\n",
    "print('R2 score:{:.2f}'.format(r2))\n",
    "\n",
    "print('R2 score Train data: {:.2f}'.format(r2_train) )\n",
    "pred_my_value = dt_model.predict([[6,171.0, 97.0,2984,14.5, 75, 1]])\n",
    "print(\"\\nThis is the prediction\",pred_my_value, '\\n')\n",
    "\n",
    "#decision tree bagging\n",
    "#let's imports the necessary packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn. linear_model import LinearRegression\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "dt_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Instantiate the bagging regressor\n",
    "\n",
    "bc = BaggingRegressor(base_estimator=dt_model, n_estimators=50, random_state=0)\n",
    "\n",
    "# Fit bce to the training set\n",
    "bc. fit(X_train, y_train) #use ravel to reshape to avide dimension warning\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Predict the labels of the training set\n",
    "y_pred_train = bc.predict(X_train)\n",
    "\n",
    "# evaluate evaluation\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmseé = np.sqrt(mse)\n",
    "\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "#the r2 for the train dataset\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "# printing the model evaluation values\n",
    "\n",
    "print('Mean absolute error: {:.2f}'.format(mae))\n",
    "print('Mean squared error: {:.2f}'.format(mse) )\n",
    "print('Root mean squared error: {:.2f}'.format(rmse) )\n",
    "print('R2 score:{:.2f}'.format(r2))\n",
    "\n",
    "print('R2 score Train data: {:.2f}'.format(r2_train) )\n",
    "\n",
    "#we can check prediction for a specific values\n",
    "pred_my_value = bc.predict([[6, 171.0, 97.0, 2984, 14.5, 75, 1]])\n",
    "print(\"\\nThis is the prediction \", pred_my_value, '\\n')\n",
    "\n",
    "#we can check prediction for a specific values\n",
    "pred_my_value = dt_model.predict([[6, 171.0, 97.0, 2984, 14.5, 75, 1]])\n",
    "print(\"\\nThis is the prediction \", pred_my_value, '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The total of training dataset (278, 1)\n",
      "\n",
      " The total of test dataset (120, 1)\n",
      "Mean absolute error: 2.01\n",
      "Mean squared error: 7.40\n",
      "Root mean squared error: 2.72\n",
      "R2 score:0.87\n",
      "R2 score Train data: 0.98\n",
      "\n",
      "This is the prediction  [20.592] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random forest\n",
    "#let's imports the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn. impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#check the dimensions of train and test data\n",
    "print('\\n The total of training dataset',x_train.shape)\n",
    "print('\\n The total of test dataset',x_test.shape)\n",
    "\n",
    "#Let perform a randomForest regression\n",
    "# Instantiate random forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=25, random_state=2)\n",
    "\n",
    "# Fit bc to the training set\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the training set\n",
    "y_pred_train = rf_model.predict(X_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = rf_model.predict(X_test)\n",
    "#print(y_pred)\n",
    "\n",
    "# evaluate evaluation\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "#the r2 for the train dataset\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "# printing the model evaluation values\n",
    "\n",
    "print('Mean absolute error: {:.2f}'.format(mae) )\n",
    "print('Mean squared error: {:.2f}'.format(mse) )\n",
    "print('Root mean squared error: {:.2f}'.format(rmse) )\n",
    "print('R2 score:{:.2f}'.format(r2))\n",
    "\n",
    "print('R2 score Train data: {:.2f}'.format(r2_train) )\n",
    "\n",
    "#we can check prediction for a specific values\n",
    "pred_my_value = rf_model.predict([[6, 171.0, 97.0, 2984, 14.5, 75, 1]])\n",
    "print(\"\\nThis is the prediction \", pred_my_value, '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 29>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mensemble\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RandomForestRegressor\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m#Visualise feature importance.\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# Create a pd.Series of features importances\u001B[39;00m\n\u001B[1;32m---> 29\u001B[0m importances \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mSeries(data\u001B[38;5;241m=\u001B[39mrf_model\u001B[38;5;241m.\u001B[39m feature_importances_,index\u001B[38;5;241m=\u001B[39m \u001B[43mX_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# Sort based on prediction importances\u001B[39;00m\n\u001B[0;32m     32\u001B[0m importances_sorted \u001B[38;5;241m=\u001B[39m importances\u001B[38;5;241m.\u001B[39msort_values()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "#Random forest\n",
    "\n",
    "#let 's imports the necessary packages\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Visualise feature importance.\n",
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rf_model. feature_importances_,index= X_train.columns)\n",
    "\n",
    "# Sort based on prediction importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='blue')\n",
    "plt.title('Features Importances')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Adaptive boosting\n",
    "\n",
    "#let 's| imports the necessary packages\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score , roc_auc_score\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "\n",
    "# Instantiate dt\n",
    "dt_model = DecisionTreeRegressor(max_depth=2, random_state=1)\n",
    "\n",
    "# Instantiate ada\n",
    "ada=AdaBoostRegressor(base_estimator=dt_model, n_estimators=180, random_state=1)\n",
    "\n",
    "# Fit ada to the training set\n",
    "ada. fit(X_train.values, y_train.values.ravel())# use ravel to avoid warning about 2d array\n",
    "\n",
    "# Predict the labels of the training set\n",
    "y_pred_train = ada.predict(X_train)\n",
    "\n",
    "#predict model\n",
    "y_pred = ada.predict(X_test)\n",
    "#print(y_pred)\n",
    "\n",
    "# evaluate evaluation\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "# printing the model evaluation values\n",
    "\n",
    "print('Mean absolute error: {:.2f}'.format(mae) )\n",
    "print('Mean squared error: {:.2f}'.format(mse))\n",
    "print('Root mean squared error: {:.2f}'.format(rmse) )\n",
    "print('R2 score:{:.2f}'.format(r2))\n",
    "\n",
    "print('R2 score Train data: {:.2f}'.format(r2_train) )\n",
    "\n",
    "#we can check prediction for a specific values\n",
    "\n",
    "pred_my_value = ada.predict([[6, 171.0, 97.0, 2984, 14.5, 75, 1]])\n",
    "#pred_my_value = ada.predict([[8,307,130,3504,12,70,1]])\n",
    "#pred_my_value = ada.predict([[5,131,103,2830,15.9,78,2]])\n",
    "#pred_my_value = ada.predict([[4,141,80,3230,20.4,81,2 ]])\n",
    "print(\"This is the prediction \", pred_my_value, '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}